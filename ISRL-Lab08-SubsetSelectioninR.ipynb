{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab on Subset Selection in R comes from p. 244-247 of \"Introduction to Statistical Learning with Applications in R\" by Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani. It was re-implemented in Fall 2016 in `tidyverse` format by Amelia McNamara and R. Jordan Crouser at Smith College.\n",
    "\n",
    "\n",
    "# 6.5.1 Best Subset Selection\n",
    "\n",
    "Here we apply the best subset selection approach to the `Hitters` data. We\n",
    "wish to predict a baseball player’s `Salary` on the basis of various statistics\n",
    "associated with performance in the previous year. Let's take a quick look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(ISLR)\n",
    "library(dplyr)\n",
    "head(Hitters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we note that the `Salary` variable is missing for some of the\n",
    "players. The `is.na()` function can be used to identify the missing observations. It returns a vector of the same length as the input vector, with a `TRUE` value\n",
    "for any elements that are missing, and a `FALSE` value for non-missing elements.\n",
    "The `sum()` function can then be used to count all of the missing elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Hitters %>%\n",
    "  select(Salary) %>%\n",
    "  is.na() %>%\n",
    "  sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that `Salary` is missing for 59 players. The `na.omit()` function\n",
    "removes all of the rows that have missing values in any variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print the dimensions of the original Hitters data (322 rows x 20 columns)\n",
    "dim(Hitters)\n",
    "\n",
    "# Drop any rows the contain missing values\n",
    "Hitters = Hitters %>%\n",
    "  na.omit()\n",
    "\n",
    "# Print the dimensions of the modified Hitters data (263 rows x 20 columns)\n",
    "dim(Hitters)\n",
    "\n",
    "# One last check: should return 0\n",
    "Hitters %>%\n",
    "  is.na() %>%\n",
    "  sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `regsubsets()` function (part of the `leaps` library) performs best subset selection by identifying the best model that contains a given number of predictors, where **best** is quantified using RSS. The syntax is the same as for `lm()`. The `summary()` command outputs the best set of variables for\n",
    "each model size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(leaps)\n",
    "regfit_full = regsubsets(Salary~., data = Hitters)\n",
    "summary(regfit_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An asterisk (\"\\*\") indicates that a given variable is included in the corresponding\n",
    "model. For instance, this output indicates that the best two-variable model\n",
    "contains only `Hits` and `CRBI`. By default, `regsubsets()` only reports results\n",
    "up to the best eight-variable model. But the `nvmax` option can be used\n",
    "in order to return as many variables as are desired. Here we fit up to a\n",
    "19-variable model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regfit_full = regsubsets(Salary~., data = Hitters, nvmax = 19)\n",
    "reg_summary = summary(regfit_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that rather than letting the results of our call to the `summary()` function print to the screen, we've saved the results to a variable called `reg_summary`. That way, we can access just the parts we need. Let's see what's in there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names(reg_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! In addition to the verbose output we get when we print the summary to the screen, the `summary()` function also returns $R^2 (\\tt{rsq})$, RSS, adjusted $R^2$, $C_p$, and BIC. We can examine these to try to select the best overall model. Let's start by looking at $R^2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reg_summary$rsq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the $R^2$ statistic increases from 32% when only\n",
    "one variable is included in the model to almost 55% when all variables\n",
    "are included. As expected, the $R^2$ statistic increases monotonically as more\n",
    "variables are included.\n",
    "\n",
    "Plotting RSS, adjusted $R^2$, $C_p$, and BIC for all of the models at once will\n",
    "help us decide which model to select. Note the `type=\"l\"` option tells `R` to\n",
    "connect the plotted points with lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up a 2x2 grid so we can look at 4 plots at once\n",
    "par(mfrow = c(2,2))\n",
    "plot(reg_summary$rss, xlab = \"Number of Variables\", ylab = \"RSS\", type = \"l\")\n",
    "plot(reg_summary$adjr2, xlab = \"Number of Variables\", ylab = \"Adjusted RSq\", type = \"l\")\n",
    "\n",
    "# We will now plot a red dot to indicate the model with the largest adjusted R^2 statistic.\n",
    "# The which.max() function can be used to identify the location of the maximum point of a vector\n",
    "adj_r2_max = which.max(reg_summary$adjr2) # 11\n",
    "\n",
    "# The points() command works like the plot() command, except that it puts points \n",
    "# on a plot that has already been created instead of creating a new plot\n",
    "points(adj_r2_max, reg_summary$adjr2[adj_r2_max], col =\"red\", cex = 2, pch = 20)\n",
    "\n",
    "# We'll do the same for C_p and BIC, this time looking for the models with the SMALLEST statistic\n",
    "plot(reg_summary$cp, xlab = \"Number of Variables\", ylab = \"Cp\", type = \"l\")\n",
    "cp_min = which.min(reg_summary$cp) # 10\n",
    "points(cp_min, reg_summary$cp[cp_min], col = \"red\", cex = 2, pch = 20)\n",
    "\n",
    "plot(reg_summary$bic, xlab = \"Number of Variables\", ylab = \"BIC\", type = \"l\")\n",
    "bic_min = which.min(reg_summary$bic) # 6\n",
    "points(bic_min, reg_summary$bic[bic_min], col = \"red\", cex = 2, pch = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that in the second step of our selection process, we narrowed the field down to just one model on any $k<=p$ predictors. We see that according to BIC, the best performer is the model with 6 variables. According to $C_p$, 10 variables. Adjusted $R^2$ suggests that 11 might be best. Again, no one measure is going to give us an entirely accurate picture... but they all agree that a model with 5 or fewer predictors is insufficient, and a model with more than 12 is overfitting.\n",
    "\n",
    "The `regsubsets()` function has a built-in `plot()` command which can\n",
    "be used to display the selected variables for the best model with a given\n",
    "number of predictors, ranked according to a chosen statistic.  The top row of each plot contains a black square for each variable selected according to the optimal model associated with that statistic. \n",
    "\n",
    "To find out more about this function, type `?plot.regsubsets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(regfit_full, scale = \"r2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, $R^2$ is maximized by the model that contains all 20 predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(regfit_full, scale = \"adjr2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusted $R^2$ downselects to just 11 predictors. We can use the `coef()` function to see which predictors made the cut:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coef(regfit_full, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(regfit_full, scale = \"Cp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$C_p$ downselects further, dropping the `LeagueN` predictor and bringing the number down to 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coef(regfit_full, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(regfit_full, scale = \"bic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that several models share a BIC close to −150. However, the model\n",
    "with the lowest BIC is the six-variable model that contains only `AtBat,\n",
    "Hits, Walks, CRBI, DivisionW,` and `PutOuts`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coef(regfit_full, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.5.2 Forward and Backward Stepwise Selection\n",
    "We can also use the `regsubsets()` function to perform forward stepwise\n",
    "or backward stepwise selection, using the argument `method=\"forward\"` or\n",
    "`method=\"backward\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Forward\n",
    "regfit_fwd = regsubsets(Salary~., data = Hitters, nvmax = 19, method = \"forward\")\n",
    "summary(regfit_fwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Backward\n",
    "regfit_bwd = regsubsets(Salary~., data = Hitters, nvmax = 19, method = \"backward\")\n",
    "summary(regfit_bwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that using forward stepwise selection, the best onevariable\n",
    "model contains only `CRBI`, and the best two-variable model additionally\n",
    "includes `Hits`. For this data, the best one-variable through six-variable\n",
    "models are each identical for best subset and forward selection.\n",
    "However, the best seven-variable models identified by forward stepwise selection,\n",
    "backward stepwise selection, and best subset selection are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coef(regfit_full, 7)\n",
    "coef(regfit_fwd, 7)\n",
    "coef(regfit_bwd, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting credit\n",
    "To get credit for this lab, please post an example where you would choose to use each of the following:\n",
    "- Best subset\n",
    "- Forward selection\n",
    "- Backward selection\n",
    "\n",
    "to [Moodle](https://moodle.smith.edu/mod/quiz/view.php?id=257886)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
