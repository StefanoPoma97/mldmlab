{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Build an Ensemble Of Machine Learning Algorithms in R\n",
    "\n",
    "Ensembles can give you a boost in accuracy on your dataset.\n",
    "\n",
    "In this post you will discover how you can create three of the most powerful types of ensembles in R.\n",
    "\n",
    "This case study will step you through Boosting, Bagging and Stacking and show you how you can continue to ratchet up the accuracy of the models on your own datasets.\n",
    "\n",
    "## Increase The Accuracy Of Your Models\n",
    "\n",
    "It can take time to find well performing machine learning algorithms for your dataset. This is because of the trial and error nature of applied machine learning.\n",
    "\n",
    "Once you have a shortlist of accurate models, you can use algorithm tuning to get the most from each algorithm.\n",
    "\n",
    "Another approach that you can use to increase accuracy on your dataset is to combine the predictions of multiple different models together.\n",
    "\n",
    "This is called an ensemble prediction.\n",
    "Combine Model Predictions Into Ensemble Predictions\n",
    "\n",
    "The three most popular methods for combining the predictions from different models are:\n",
    "*    Bagging. Building multiple models (typically of the same type) from different subsamples of the training dataset.\n",
    "*    Boosting. Building multiple models (typically of the same type) each of which learns to fix the prediction errors of a prior model in the chain.\n",
    "*    Stacking. Building multiple models (typically of differing types) and supervisor model that learns how to best combine the predictions of the primary models.\n",
    "\n",
    "This post assumes you are generally familiar with machine learning algorithms and ensemble methods and that you are looking for information on how to create ensembles with R.\n",
    "\n",
    "## Ensemble Machine Learning in R\n",
    "\n",
    "You can create ensembles of machine learning algorithms in R.\n",
    "\n",
    "There are three main techniques that you can create an ensemble of machine learning algorithms in R: Boosting, Bagging and Stacking. In this section, we will look at each in turn.\n",
    "\n",
    "Before we start building ensembles, let’s define our test set-up.\n",
    "\n",
    "## Test Dataset\n",
    "\n",
    "All of the examples of ensemble predictions in this case study will use the ionosphere dataset.\n",
    "\n",
    "This is a dataset available from the UCI Machine Learning Repository. This dataset describes high-frequency antenna returns from high energy particles in the atmosphere and whether the return shows structure or not. The problem is a binary classification that contains 351 instances and 35 numerical attributes.\n",
    "\n",
    "Let’s load the libraries and the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installl Packages\n",
    "list.of.packages <- c(\"caret\",\"caretEnsemble\",\"mlbench\")\n",
    "new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,\"Package\"])]\n",
    "if(length(new.packages)) install.packages(new.packages)\n",
    "\n",
    "# Load libraries\n",
    "library(mlbench)\n",
    "library(caret)\n",
    "library(caretEnsemble)\n",
    " \n",
    "# Load the dataset\n",
    "data(Ionosphere)\n",
    "dataset <- Ionosphere\n",
    "dataset <- dataset[,-2]\n",
    "dataset$V1 <- as.numeric(as.character(dataset$V1))\n",
    "head(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the first attribute was a factor (0,1) and has been transformed to be numeric for consistency with all of the other numeric attributes. Also note that the second attribute is a constant and has been removed.\n",
    "\n",
    "For more information, see the description of the Ionosphere dataset on the UCI Machine Learning Repository.\n",
    "\n",
    "See this summary of published world-class results on the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking Algorithms\n",
    "\n",
    "You can combine the predictions of multiple caret models using the caretEnsemble package.\n",
    "\n",
    "Given a list of caret models, the caretStack() function can be used to specify a higher-order model to learn how to best combine the predictions of sub-models together.\n",
    "\n",
    "Let’s first look at creating 5 sub-models for the ionosphere dataset, specifically:\n",
    "*   Linear Discriminate Analysis (LDA)\n",
    "*    Classification and Regression Trees (CART)\n",
    "*    Logistic Regression (via Generalized Linear Model or GLM)\n",
    "*    k-Nearest Neighbors (kNN)\n",
    "*    Support Vector Machine with a Radial Basis Kernel Function (SVM)\n",
    "\n",
    "Below is an example that creates these 5 sub-models. Note the new helpful caretList() function provided by the caretEnsemble package for creating a list of standard caret models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create submodels\n",
    "\n",
    "control <- trainControl(method=\"repeatedcv\", number=10, repeats=3, savePredictions=TRUE, classProbs=TRUE)\n",
    "algorithmList <- c('lda', 'rpart', 'glm', 'knn', 'svmRadial')\n",
    "set.seed(seed)\n",
    "models <- caretList(Class~., data=dataset, trControl=control, methodList=algorithmList)\n",
    "results <- resamples(models)\n",
    "summary(results)\n",
    "dotplot(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the SVM creates the most accurate model with an accuracy of 94.66%.\n",
    "\n",
    "When we combine the predictions of different models using stacking, it is desirable that the predictions made by the sub-models have low correlation. This would suggest that the models are skillful but in different ways, allowing a new classifier to figure out how to get the best from each model for an improved score.\n",
    "\n",
    "If the predictions for the sub-models were highly corrected (>0.75) then they would be making the same or very similar predictions most of the time reducing the benefit of combining the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation between results\n",
    "modelCor(results)\n",
    "splom(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that all pairs of predictions have generally low correlation. The two methods with the highest correlation between their predictions are Logistic Regression (GLM) and kNN at 0.517 correlation which is not considered high (>0.75).\n",
    "\n",
    "Let’s combine the predictions of the classifiers using a simple linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack using glm\n",
    "stackControl <- trainControl(method=\"repeatedcv\", number=10, repeats=3, savePredictions=TRUE, classProbs=TRUE)\n",
    "set.seed(seed)\n",
    "stack.glm <- caretStack(models, method=\"glm\", metric=\"Accuracy\", trControl=stackControl)\n",
    "print(stack.glm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have lifted the accuracy to 94.99% which is a small improvement over using SVM alone. This is also an improvement over using random forest alone on the dataset, as observed above.\n",
    "\n",
    "We can also use more sophisticated algorithms to combine predictions in an effort to tease out when best to use the different methods. In this case, we can use the random forest algorithm to combine the predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack using random forest\n",
    "set.seed(seed)\n",
    "stack.rf <- caretStack(models, method=\"rf\", metric=\"Accuracy\", trControl=stackControl)\n",
    "print(stack.rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this has lifted the accuracy to 96.26% an impressive improvement on SVM alone."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
